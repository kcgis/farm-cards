{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Farm Card Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Background on Farm Cards\n",
    "2. Notebook Setup\n",
    "3. The Main Process\n",
    "4. Alterations\n",
    "6. Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Everything you're seeing here is *open source* and publicly available [in our GitHub repo](https://github.com/kcgis/farm-cards).\n",
    "\n",
    "If you like what you see and want to use it, please do! It's not a fully-fledged piece of software so much as a bunch of code, but you're welcome to it. For all I care, turn around and sell it! Build it into something! Just mind the license!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I'm Josh Carlson, the GIS Cadastral Analyst for Kendall County GIS.\n",
    "\n",
    "![author image](images/author_image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Get in touch!**\n",
    "\n",
    "platform|username\n",
    "-|-\n",
    "OpenStreetMap|[jdcarls2](https://www.openstreetmap.org/user/jdcarls2)\n",
    "AGOL|[carlsonj9](https://www.arcgis.com/home/user.html?user=carlsonj9)\n",
    "Esri Community|[jcarlson](https://community.esri.com/t5/user/viewprofilepage/user-id/363906)\n",
    "Discord|jcarlson#7300\n",
    "GitHub|[jdcarls2](https://github.com/jdcarls2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This presentation *is* the Jupyter Notebook that is running the code, as well as the slides themselves.\n",
    "\n",
    "I want this Notebook to be as helpful as possible on its own, so the markdown cells are a bit verbose, and not the typical bullet point slideshow.\n",
    "\n",
    "There is a *lot* in this notebok to get through. If I'm honest, maybe a bit too much for 30 minutes.\n",
    "\n",
    "I will probably skim through certain sections. I would rather leave time at the end for you to ask questions than use up my time explaining the parts nobody wants to know about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What Even *Are* \"Farm Cards\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A farm card is an archaic term for the assessment record of a rural property, formerly kept on literal cards.\n",
    "\n",
    "![sample farm card](images/sample_card.png)\n",
    "\n",
    "*Image credits: IDR Publication 122*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nowadays, it refers to the list of landuse / soil areas in an agricultural parcel and their values. This notebook is concerned with the means by which said list is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To assist counties in this, and in accordance with the Farmland Assessment Law, the Illinois Department of Revenue provides the following publication:\n",
    "\n",
    "[Publication 122: Instructions for Farmland Assessments](https://www2.illinois.gov/rev/research/publications/pubs/Documents/Pub-122.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## IDR Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Landuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generally speaking, farm valuation is primarily concerned with:\n",
    "* Cropland\n",
    "* Pasture\n",
    "* \"Other farmland\"\n",
    "* Wasteland\n",
    "* Homesites / Buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are also other areas, like roads and rivers, which are important in identifying areas *not* to be valued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### County Landuse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To track these areas / features, the Assessment Office maintains a **Landuse** layer in our GIS portal.\n",
    "\n",
    "Using high-resolution imagery and current property boundaries as a guide, the Assessment Office makes updates and corrections to this layer as necessary to accurately reflect the current landuse category, according to Publication 122 guidelines.\n",
    "\n",
    "![landuse](images/landuse_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Soils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Following the recommendations of Publication 122, Kendall County uses [detailed soil data](https://www.nrcs.usda.gov/wps/portal/nrcs/main/soils/survey/geo/) prepared by NRCS.\n",
    "\n",
    "Esri maintains a [**Living Atlas** layer](https://arcgis.com/home/item.html?id=06e5fd61bdb6453fb16534c676e1c9b9#overview) that can be used for this, but we chose instead to host a copy of the dataset, clipped to the Kendall County Region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Why a Subset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Our layer is much smaller, and performs faster\n",
    "2. The Esri-provided layer is considered **premium content**, and is not available to public viewers\n",
    "3. The output needed from the calculation is easier if the `musym`, or 'map unit symbol', field can be split, so control over schema is needed:\n",
    "    1. Original: `musym = 119D`, specifies soil type *and* slope in single value\n",
    "    2. Split: `soild_type = 119` + `slope = D`, one element tracked per field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Individual Soil Weighting Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Per IDR, there is a 10-step proccedure for assessing farmland:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Get legal boundaries and aerial imagery\n",
    "2. Overlay soil types\n",
    "3. Using a combination of aerial imagery and on-site inspection, classify landuse areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Between GIS and the Assessment office, steps 1-3 are already taken care of before we even started this notebook, and are continuously amended as needed throughout the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "4. Determine acreage of each soil type within each landuse category\n",
    "5. Determine PI ratings for soil types, using IDR reference table as necessary\n",
    "6. Adjust PI values for slope and erosion\n",
    "7. Determine EAV per acre of soil/slope/landuse combination based on IDR reference table\n",
    "8. Calculate assessed value by multiplying EAV with number of acres\n",
    "9. Subtotal acres and values by soil/slope/landuse\n",
    "10. Sum by parcel for full assessed value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To be clear, many of these steps are simply formulas besed on attributes avd predetermined coefficients. In our case in particular, the assessment software used performs said calculations itself, and needs only the input attributes and acreage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Put simply, most of this notebook is **step 4** (and part of step 9) of the process.\n",
    "\n",
    "> Determine the acreage of each soil type within each land use category that will be assessed by productivity. The measurement may be made using a planimeter, grid, electronic calculator, or computerized mapping system (GIS, autocad, map info, etc.) whereby the various maps (soil, aerial, tax) may be digitized or scanned-in as layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's worth pointing out that we *could* perform more of the steps here in our notebook, we (Kendall County) just don't need to. If *you do*, stick around to the end! We'll discuss extending this notebook for additional functionality, and we'll cover those other steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Set Up Notebook Environment\n",
    "\n",
    "As with any bit of code, there are a few things we need to get situated before we really start in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Import Modules\n",
    "\n",
    "We'll be using the following modules in this notebook:\n",
    "\n",
    "* GeoPandas\n",
    "    * Pandas\n",
    "    * Numpy\n",
    "* Requests\n",
    "* MatPlotLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [GeoPandas](https://geopandas.org/)\n",
    "\n",
    "* Spatially enabled extension of **[pandas](https://pandas.pydata.org/)**, a popular Python data manipulation module, itself building off of **[numpy](https://numpy.org/)**\n",
    "    * For a handful of operations, it's simpler to access these modules directly\n",
    "* Uses **[Shapely](https://shapely.readthedocs.io/en/latest/)** to handle spatial operations\n",
    "* Uses **[Fiona](https://fiona.readthedocs.io/en/latest/README.html)** for reading and writing spatial files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [Requests](https://docs.python-requests.org/en/master/)\n",
    "\n",
    "* Easily encode URL requests\n",
    "* Parse response in a variety of formats\n",
    "* In this case, used to query ArcGIS Server REST endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### [MatPlotLib](https://matplotlib.org/)\n",
    "\n",
    "* Well-developed visualization library\n",
    "* **GeoPandas** (and **pandas**) written with deep MatPlotLib integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A Few Global Variables\n",
    "\n",
    "There are a few variables that we'll declare here at the top. We do this because:\n",
    "1. It makes it easier to reference\n",
    "2. Users wishing to adapt this for their own use don't need to look all over the notebook for where to change things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Spatial reference for layers\n",
    "sr = \"{'wkid': 3435}\"\n",
    "\n",
    "# Parcels REST service\n",
    "parcels_url = 'https://maps.co.kendall.il.us/server/rest/services/Hosted/Current_Cadastral_Features/FeatureServer/1/query?'\n",
    "\n",
    "# SSURGO Soils REST service\n",
    "soils_url = 'https://maps.co.kendall.il.us/server/rest/services/Hosted/Assessor_Soils/FeatureServer/0/query?'\n",
    "\n",
    "# Landuse REST service\n",
    "landuse_url = 'https://maps.co.kendall.il.us/server/rest/services/Hosted/Assessor_Landuse/FeatureServer/0/query?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parcels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constructing the Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this example, we're using a local file, `input_pins.txt`, which contains the PINs listed below:\n",
    "\n",
    "```txt\n",
    "07-35-400-005\n",
    "07-36-300-004\n",
    "07-36-300-006\n",
    "07-36-100-001\n",
    "07-35-200-005\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll use a `with... as` command to temporarily open the file and read its contents into a variable.\n",
    "\n",
    "Using Python *list comprehension*, `[something(x) for x in y]`, we can succinctly compile a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('resources/input_pins.txt', 'r') as file:\n",
    "    pin_list = [\"'\" + pin + \"'\" for pin in file.read().split('\\n')]\n",
    "\n",
    "pin_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Why the single-quotes in the PINs?*\n",
    "\n",
    "Because these PINs are going to populate the `where` clause we submit to the REST service. The clause has to be formatted as valid SQL in order to evaluate.\n",
    "\n",
    "In our query, we'll be filtering the results using `IN` on a **string** field, so each value needs to be quoted out, and being SQL, must be single-quotes to be read as string values instead of column names.\n",
    "\n",
    "Also, rather than concatenate multiple strings, we're using Python's *f-strings* to build the where clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"pin IN ({','.join(pin_list)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we assemble the query. For performance, we'll also limit the output fields to only those necessary for the calculation, `pin` and `gross_acres`. We supply the spatial reference defined at the top, and specify GeoJSON as the output format.\n",
    "\n",
    "We then submit that query to the REST endpoint and use GeoPandas to read the response into a GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parcels_params = {\n",
    "    'where': f\"pin IN ({','.join(pin_list)})\",\n",
    "    'outFields': 'gross_acres, pin',\n",
    "    'outSR': sr,\n",
    "    'f': 'geojson'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parcels = requests.get(parcels_url, parcels_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_df = gp.read_file(parcels.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To check on the output, we'll call the method `head` on our dataframe. This returns up to 5 of the first rows of the dataframe, and is an easy way to glance at a subset of the data when working with larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With spatial data it can be helpful to see the shapes, so we'll also make use of the `plot` method.\n",
    "\n",
    "Note that in standard pandas, this returns a graph. In GeoPandas, however, [plot](https://geopandas.org/docs/reference/api/geopandas.GeoDataFrame.plot.html?highlight=plot#geopandas.GeoDataFrame.plot) will look for a geometry column to visualize instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_df.plot(column='pin', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adding Calculated Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to accurately calculate our farm cards, we'll be using the calculated area of the geometry in the given spatial reference. *Deeded* acreage trumps *actual* acreage, though, so we need to be able to scale our calculations accordingly.\n",
    "\n",
    "To do this, we'll create a new column in the dataframe, `calc_area`. GeoDataFrames have a built-in property `area`, which returns the area of the shape in the given spatial reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that dataframes are similar to dictionaries in other languages; new keys / columns can be defined simply by assigning a value to `dataframe['newcolumn']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_df['calc_area'] = p_df.area\n",
    "\n",
    "p_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You'll notice the calculated area is in square feet, not acres. The calculated units don't actually matter, though, as will be evident later on. For now, we have enough to move on to our other layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Landuse and Soils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Spatial Filter\n",
    "\n",
    "In order to get only those features which are relevant to the above parcels, we need need to supply a **spatial filter** for our query.\n",
    "\n",
    "If we wanted to be fancy, we *could* submit the individual geometries themselves. But let's keep things simple. As we are working with contiguous parcels in a small area, we just need an envelope that contains all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "GeoDataFrames have another useful property, `total_bounds`. This returns an array of the min/max x and y of all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p_df.total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll be constructing an **esriGeometryEnvelope** for the spatial filter, which needs to be in the format `'min_x, min_y, max_x, max_y'`.\n",
    "\n",
    "We can't use `join` on *float* objects, so we'll use some more *list comprehension* to convert the list to *strings* first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bbox = ','.join([str(i) for i in p_df.total_bounds])\n",
    "\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constructing Queries\n",
    "\n",
    "The queries for our landuse and soils data will be the same.\n",
    "\n",
    "We want all the fields of all the features that *intersect* with the `bbox` geometry we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "farm_params = {\n",
    "    'where': '1=1',\n",
    "    'outFields': '*',\n",
    "    'returnGeometry': True,\n",
    "    'geometryType': 'esriGeometryEnvelope',\n",
    "    'geometry': bbox,\n",
    "    'spatialRel': 'esriSpatialRelIntersects',\n",
    "    'outSR': sr,\n",
    "    'f': 'geojson'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Soils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soils = requests.get(soils_url, farm_params)\n",
    "\n",
    "s_df = gp.read_file(soils.text)\n",
    "\n",
    "s_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "landuse = requests.get(landuse_url, farm_params)\n",
    "\n",
    "l_df = gp.read_file(landuse.text)\n",
    "\n",
    "l_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wrap it Up: Visualization\n",
    "\n",
    "Before moving on, let's visualize our dataframes all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(18,8), sharex=True, sharey=True)\n",
    "\n",
    "p_df.plot(column='pin', ax=axs[0])\n",
    "s_df.plot(column='musym', ax=axs[1])\n",
    "l_df.plot(column='landuse_type', ax=axs[2])\n",
    "\n",
    "axs[0].set_title('Parcels')\n",
    "axs[1].set_title('Soils')\n",
    "axs[2].set_title('Landuse')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overlay Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have our intersecting dataframes, now we need to bring them together. We'll be using the GeoPandas method `overlay`, which combines two dataframes based on a spatial relationship.\n",
    "\n",
    "For our purposes, we will be using **intersection**, as we are only interested in the areas that truly overlap. Don't worry if there's a warning that pops up. That just means that some of the intersected features were either lines or points, and were dropped. In this case, that's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = gp.overlay(p_df, s_df, how='intersection')\n",
    "df = gp.overlay(df, l_df, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.plot(column='pin', edgecolor='black', figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Looks great! But when we look at the schema, we've got a few too many columns here from the overlays. Let's clean those up first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Removing Extra Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For our calculations, we only need a few of those fields. We'll define the 'keeper' fields and delete everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "keepers = [\n",
    "    'gross_acres',\n",
    "    'gis_acres',\n",
    "    'calc_area',\n",
    "    'pin',\n",
    "    'soil_type',\n",
    "    'slope',\n",
    "    'landuse_type',\n",
    "    'geometry'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll combine some *list comprehension* with a *ternary operator* (`func(x) if condition else other_func`) here to keep things succinct.\n",
    "\n",
    "Including `inplace=True` modifies the existing dataframe without needing to reassign variables or create additional objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[c for c in df if c not in keepers], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's check out the schema now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Perfect! Now we're ready for the main calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculate Area of Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As promised, here's where the calculated area matters. You might have noticed that the resulting pieces from the overlay all inherited the `calc_area` attribute of the parent parcel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[['pin', 'calc_area']].sort_values(by='pin').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll now calculate the new area of the part. Using the method `assign`, we can create a new column temporarily in our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.assign(part_area = df.area)[['pin', 'calc_area', 'part_area']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With these two fields, `calc_area` and `part_area`, we can now derive the ratio of the part to the whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.assign(\n",
    "    part_area = df.area,\n",
    "    area_ratio = lambda x: x['part_area'] / x['calc_area']\n",
    ")[['pin', 'calc_area', 'part_area', 'area_ratio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can  multiply that ratio against the *deeded acreage* value in `gross_acres` to get the acres of each individual part, scaled to match the legal area of the parcel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.assign(\n",
    "    part_area = df.area,\n",
    "    area_ratio = lambda x: x['part_area'] / x['calc_area'],\n",
    "    part_acres = lambda x: x['area_ratio'] * x['gross_acres']\n",
    ")[['pin', 'calc_area', 'part_area', 'area_ratio', 'gross_acres', 'part_acres']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, those were just *temporary* outputs. `df` hasn't actually changed. Both the `part_area` and `area_ratio` columns, while important to the calculation, are just intermediate outputs.\n",
    "\n",
    "By combining the calculations into a single statement, we can reduce unnecessary outputs.\n",
    "\n",
    "$$\n",
    "Ac_{part} = Ac_{whole} * \\frac{A_{part}}{A_{whole}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['part_acres'] = df.area / df['calc_area'] * df['gross_acres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tidying Up and Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dropping Unnecessary Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that we have our `part_acres`, we really don't need the other area values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['gross_acres', 'calc_area'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Field Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here in Kendall County, our Assessments Office uses [Devnet](https://www.devnetinc.com/) software. In this program, farm cards are imported in a very specific format. We'll go through some of the fields to make them import-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### PIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The PIN needs to be given *without* hyphenation.\n",
    "\n",
    "String columns in a dataframe have a `str` method that allows us to apply standard Python [string operators](https://docs.python.org/3/library/string.html) to each element in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:,'pin'] = df['pin'].str.replace('-', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Landuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Landuse follows a defined coded domain. However, this domain is actually strings of numeric characters, as opposed to true numbers.\n",
    "\n",
    "The landuse GIS layer we used has the domain as numbers, though. (Even as strings, though it's possible that a dataframe would wrongly infer the field to be numeric given its content.)\n",
    "\n",
    "To make this field ready for import, we have to insert a '0' before the number in the column and cast it as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'landuse_type'] = '0' + df['landuse_type'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look-see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Perfect! We're nearly there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A Note on `.loc[]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Anyone who has used pandas enough will probably have seen the `SettingwithCopyWarning` at some point. For editing values of a dataframe as opposed to merely viewing them, it is preferable to use the `.loc` accessor to ensure that values are truly being changed.\n",
    "\n",
    "See [the pandas docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-view-versus-copy) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Aggregating the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next, we will be aggregating the data. Because our overlaid data returned singlepart geometries, there may be multiple rows in the output that have the same PIN/landuse/soil combinations.\n",
    "\n",
    "It's not strictly necessary for the import, but it makes the output a *lot* nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "out_cols = ['pin', 'soil_type', 'slope', 'landuse_type']\n",
    "\n",
    "print('Before grouping: ', len(df))\n",
    "\n",
    "df = df.groupby(by=out_cols, as_index=False).sum()\n",
    "\n",
    "print('After grouping: ', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rounding and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You read that right, we will be doing *rounding*. The assessment database we use only accepts acreage values up to 4 decimal places anyway. This also helps identify lingering features that are *very* small (`6.808778e-11`, for example) by rounding them off to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'part_acres'] = round(df.loc[:, 'part_acres'], 4)\n",
    "\n",
    "df[df['part_acres'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll subset our dataframe to remove those `0` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df.loc[:, 'part_acres'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## THE FINISH LINE\n",
    "\n",
    "It's finally here! It's time to export our data to an importable `.txt` file. Dataframes have a `to_csv()` method that, despite the name, can export to any text-based file format.\n",
    "\n",
    "We'll specify `\\t` (a tab character) as the separator, to keep with the expected format of the import file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'farm_output.txt', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('farm_output.txt', 'r') as output:\n",
    "    print(output.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Alterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, this was cool and all, but what if your process doesn't look like mine? I'll leave it to you to handle the specifics, but in this section, we'll talk about ways this process can be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inputs\n",
    "\n",
    "If your data isn't coming from a service, you can still do this! There are many ways to get your GIS data into GeoPandas to work with it.\n",
    "\n",
    "If you open a full dataset, you can easily filter the GeoDataFrame once it's created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Shapefiles (and other files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Is your data in a *shapefile*? (My sympathies.)\n",
    "\n",
    "Try the GeoPandas method **[geopandas.read_file](https://geopandas.org/docs/reference/api/geopandas.read_file.html#geopandas.read_file)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gp.read_file('resources/input_pins.shp').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that this will work with zipped shapefiles, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gp.read_file('resources/input_pins.zip').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can *also* provide a spatial filter in the **read_file** method, or limit the rows/columns being read into the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gp.read_file('resources/input_pins.shp',\n",
    "             ignore_fields=['pin_dashle', 'parcel_typ', 'created_do', 'created_da', 'retired_do', 'retired_da', 'legal', 'tax_status', 'township', 'municipali']\n",
    "            ).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are other (admittedly less common) filetypes that can be read directly into a GeoPandas dataframe, and additional options for doing so, but I'll leave that to you to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SQL DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There *are* ways to read an SQL query directly into a dataframe, if that's what you're working with. I don't happen to have a live DB connection to demo this for you, but you have a couple options.\n",
    "\n",
    "- PostgreSQL + PostGIS, or SpatiaLite\n",
    "- Other DB types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you're using PostGIS (good for you!), GeoPandas has a method **[read_postgis](https://geopandas.org/docs/reference/api/geopandas.read_postgis.html#geopandas.read_postgis)** for this. It might look like:\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine  \n",
    "db_connection_url = \"postgres://myusername:mypassword@myhost:5432/mydatabase\"\n",
    "con = create_engine(db_connection_url)  \n",
    "sql = \"SELECT geom, highway FROM roads\"\n",
    "df = geopandas.read_postgis(sql, con)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Other DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you happen to be on a different database platform, pandas has its own **[read_sql](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html)** method. You'll need to separately import pandas, then have an additional step getting it into GeoPandas, but it's not difficult.\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine  \n",
    "db_connection_url = \"postgres://myusername:mypassword@myhost:5432/mydatabase\"\n",
    "con = create_engine(db_connection_url)  \n",
    "sql = \"SELECT geom, highway FROM roads\"\n",
    "df = pandas.read_sql(sql, con)\n",
    "gdf = geopandas.GeoDataFrame(df, geometry='shape-column-name', crs='some-spatial-reference-wkt')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As with the preceding section between GeoPandas and pandas, you can also write your results to all of the same formats and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Doing the Valuation, too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Maybe you'd like to calculate the values here? You can! All you need are the tables from Publication 122 (Revised from [Bulletin 810](https://www2.illinois.gov/rev/localgovernments/property/Documents/B810.pdf)) as their own dataframes.\n",
    "\n",
    "They make up most of Publication 122, and are, unhelpfully, in PDF form. But once you get the values into a CSV or similar, just load it in much like our we did the PINs earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Soil Productivity Index ($PI$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "GeoPandas expects there to be a spatial component to datasets. There is none here, so we use **pandas** to create the dataframe instead. Plus pandas is better at inferring datatypes based on the contents of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pi_df = pd.read_csv('resources/soil_PI_2021.csv')\n",
    "\n",
    "pi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Slope and Erosion Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Though there is a full table of PI adjustments for each 1% from 0 to 43, we don't have the slope values in such detail. Working with NRCS soil data, we have the following classes based on the map symbol's slope letter:\n",
    "\n",
    "Letter Code|% Slope\n",
    "-|:-:\n",
    "None / A|0-2%\n",
    "B|2-5%\n",
    "C|5-10%\n",
    "D|10-15%\n",
    "E|15-18%\n",
    "F|18-35%\n",
    "G|35-70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Per Pub 122:\n",
    "\n",
    "> Because Table 3 cannot be used with slope ranges, use a central point of the slope ranges unless a better determinant of slope is available.\n",
    "\n",
    "For our case, we'll use a central value of each class to determine the coefficient to apply to the PI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Within each slope class, the erosion number further modifies the coefficient, and not consistently. That is, moderate erosion on flat terrain will impact productivity less than moderate erosion on steep terrain.\n",
    "\n",
    "The various combinations and coefficients reside in their own table, which is maintained by the Assessments Office. We'll pull it in from a CSV as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "se_df = pd.read_csv('resources/soil_slope_erosion_2021.csv')\n",
    "\n",
    "se_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Merge DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've got our original output dataframe from before, `df`, plus our two new dataframes with their overlapping columns.\n",
    "\n",
    "For this, we'll use **[merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)**, which can perform database-style table joins based on column values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Productivity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = df.merge(pi_df, how='left', left_on='soil_type', right_on='map_symbol', suffixes=('','_desc'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Slope and Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = df.merge(se_df, how='left', left_on='slope', right_on='erosion_code')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adusted $PI$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To get the adusted $PI$, we just need to multiply the value from the soils table with the coefficients.\n",
    "\n",
    "But! We need to do so based on the *favorability* of the soil type. Here's what we'll do:\n",
    "1. Create a new field, `adj_PI`, using the 'Favorable' coefficient\n",
    "2. Use **where** to replace values matching a condition, in this case features w/ 'Unfavorable', while retaining original values for those which do not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df['adj_PI'] = df['productivity_index'] * df['coeff_fav']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[['adj_PI']] = df[['adj_PI']].where(df['favorability'] == 'Favorable', df['productivity_index'] * df['coeff_unf'], axis=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We don't actually *have* unfavorable soil types in this sample, but if there were, the `adj_PI` value would now be adjusted accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Merge in the Equalized Assessed Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's bring in *another* table. **Table 1** from Pub 122 contains the certified per-acre EAV for a given productivity index. And don't be fooled by table 1's headers!\n",
    "\n",
    "Even though the second to last column is titled **Equalized Assessed Value** (something you might shorten to, y'know, *E-A-V*), whenever Publication 122 makes reference to an EAV in their instructions, they are referring to the **Certified Value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "eav_df = pd.read_csv('resources/eav_2021.csv')\n",
    "\n",
    "eav_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $PI < 82$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Before proceeding, it's worth pointing out: 82 is the lowest PI value for which there is a certified value, but **it is not the lowest possible PI**, especially after adjusting for slope and erosion in the prior steps.\n",
    "\n",
    "Following the [IDR's document on the topic](https://www2.illinois.gov/rev/localgovernments/property/Documents/PiBelow82.pdf), there is a correct way to evaluate the EAV for a PI below 82.\n",
    "\n",
    "For a low PI of $PI_{n}$ under the minimum certified PI $PI_{min}:\n",
    "\n",
    "$$\n",
    "EAV^{PI_{n}} = EAV^{PI_{min}} - \\left(\\frac{EAV^{PI_{min+5}} - EAV^{PI_{min}}}{5} * (min - n)\\right) \\vee \\frac{EAV^{PI_{min}}}{3}\n",
    "$$\n",
    "\n",
    "Whichever is greater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Put in the certified 2021 values, this would be:\n",
    "$$\n",
    "EAV^{PI_{n}} = 199.29 - \\left(\\frac{207.47 - 199.29}{5} * (82 - n)\\right) \\vee \\frac{199.29}{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Populating the Sub-82 Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using that formula, we can now populate all possible PI values below 82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sub82 = pd.DataFrame({'avg_PI': np.arange(1,82)})\n",
    "\n",
    "sub82['eav'] = 199.29 - (((207.47-199.29)/5)*(82-sub82['avg_PI']))\n",
    "\n",
    "print(f'Floor: {199.29/3:0.5}')\n",
    "\n",
    "sub82.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that even a PI of 1 is above the calculated floor. That value will really only begin to matter in Other Farmland areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Append New Values to the EAV Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "eav_df = eav_df.append(sub82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To successfully merge the EAV into our main dataframe, we've got to round our `adj_PI` values to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[['adj_PI']] = df[['adj_PI']].round()\n",
    "\n",
    "df = df.merge(eav_df, how='left', left_on='adj_PI', right_on='avg_PI')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Apply Landuse Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Landuse is simple. For the big three landuse types, **cropland, pasture, and other farmland**, it's a simple division. Nearly everything else is zeroed out (hydro, roadways), or assessed separately (homesites).\n",
    "\n",
    "landuse_type|landuse_desc|eav_adj\n",
    "-|-|-\n",
    "02|Cropland|$EAV*1$\n",
    "03|Permanent Pasture|$\\frac{EAV}{3}$\n",
    "04|Other Farmland|$\\frac{EAV}{6}$\n",
    "\n",
    "For **contributory wasteland**, we assess the land at 1/6 of the EAV of the *lowest PI of cropland certified by IDR*, which for 2021, happens to be **82**. This results in an EAV of **$33.22**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Create and Populate New Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To save us a series of filters and calculations, we'll create the new `eav_adj` field with a default value equal to  the `eav`, which is correct for cropland.\n",
    "\n",
    "We'll then use **where** to assign all non-cropland areas to **0**, which takes care of most everything else.\n",
    "\n",
    "Then we'll run calculations for the remaining 3 landuse types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['eav_adj']=0\n",
    "\n",
    "df[['eav_adj']] = df[['eav']].where(df['landuse_type']=='02', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# permanent pasture\n",
    "df.loc[df['landuse_type']=='03', 'eav_adj'] = df['eav']/3\n",
    "\n",
    "# other farmland\n",
    "df.loc[df['landuse_type']=='04', 'eav_adj'] = df['eav']/6\n",
    "\n",
    "# # contributory wasteland\n",
    "df.loc[df['landuse_type'] == '05', 'eav_adj'] = 33.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Just to check, let's grab a random sample (the top rows don't show any landuse types that were calculated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df[['landuse_type', 'eav', 'eav_adj']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multiply Adjusted EAV by Acres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Last step: multiply our adjusted EAV by the acres in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df['value'] = df['part_acres'] * df['eav_adj']\n",
    "\n",
    "df[['pin', 'soil_type', 'slope', 'landuse_type', 'part_acres', 'value']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That's it! You just calculated your farmland values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Standalone Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*This is all great*, you say, *but maybe I don't want to boot up this notebook every time I need new farm values.*\n",
    "\n",
    "Not to worry!\n",
    "\n",
    "Except for the PINs, there was no other point at which user input is necessary. Because of this, we can wrap up everything we did so far into a single `farm-cards.py` script, which has already been done.\n",
    "\n",
    "Here in the notebook, we can treat this like its own module, importing it and calling the function defined therein. \n",
    "\n",
    "Because the script is meant to be run on its own, there are a few differences. We'll throw a ? on there to pull up the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from farm_cards import calc_farms\n",
    "\n",
    "calc_farms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's actually run the script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df2 = calc_farms(\n",
    "    pin_list = ['01-01-400-005', '01-01-400-002'],\n",
    "    out_path = 'farm_output2.txt',\n",
    "    return_df = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One of the parameters added was `return_df`, which, when set to `True`, will also return a dataframe object from running the script. Unless otherwise defined, it defaults to false, but it can be helpful to look at the output dataframe if the file doesn't look right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "4.0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
